/*! \page tutorial_users Tutorials
This page references all the tutorials to use and contribute to ViSP.

- \subpage tutorial_started

- \subpage tutorial_linear_algebra

- \subpage tutorial_image

- \subpage tutorial_imgproc

- \subpage tutorial_calib

- \subpage tutorial_rendering

- \subpage tutorial_tracking

- \subpage tutorial_detection

- \subpage tutorial_detection_dnn

- \subpage tutorial_segmentation

- \subpage tutorial_computer_vision

- \subpage tutorial_vs

- \subpage tutorial_munkres

- \subpage tutorial_bridge

- \subpage tutorial_tools

- \subpage tutorial_coding

- \subpage tutorial_contrib

*/

/*! \page tutorial_started Getting started
This page introduces the user to the way to start with ViSP.

- \subpage tutorial-getting-started <br>This tutorial shows how to build a project that uses ViSP and CMake to read and display an image.
- \subpage tutorial-getting-started-makefile <br>This tutorial shows how to build a project that uses ViSP without CMake using `visp-config` and `pkg-config` script called in a classical Makefile.
- \subpage tutorial-getting-started-naoqi <br>This tutorial shows how to build a project that uses ViSP on NAOqi OS running on NAO, Romeo or Pepper humanoid robots.
- \subpage tutorial-import-visp-into-EclipseIDE <br>This tutorial explains how to import a CMake project in Eclipse IDE.

*/

/*! \page tutorial_linear_algebra Linear algebra operations
This page introduces the user to linear algebra operations with ViSP.

- \subpage tutorial-basic-linear-algebra <br>This tutorial gives some information concerning basic linear algebra operations implementation for vector and matrix multiplication.

*/

/*! \page tutorial_image Image manipulation
This page introduces the user to the way to get, to filter or to render images.

- \subpage tutorial-image-display <br>In this tutorial you will learn how to display an image in a window and how to down scale the window size to be able to display images that are larger than the screen resolution.
- \subpage tutorial-image-display-overlay <br>In this tutorial you will learn how to display points, lines, circles, rectangles in overlay in an image display window.
- \subpage tutorial-basic-drawings <br>In this tutorial you will learn how to modify an image to draw points, lines, circles, rectangles.
- \subpage tutorial-grabber <br>This tutorial shows how to acquire images from a camera.
- \subpage tutorial-image-filtering <br>This tutorial shows how to filter an image with ViSP.
- \subpage tutorial-simu-image <br>This tutorial shows how to project the image of a planar scene to a given camera position.
- \subpage tutorial-video-manipulation <br>In this tutorial you will learn how to manipulate a video or a sequence of successives images in order to rename the images, convert images format, or select some images that will constitute a dataset typically for deep learning purpose.

*/

/*! \page tutorial_imgproc Image processing
This page introduces some image processing methods.

- \subpage tutorial-imgproc-brightness <br>This tutorial will show you some simple techniques to adjust or improve the brightness / contrast of an image.
- \subpage tutorial-imgproc-contrast-sharpening <br>This tutorial will show you some simple techniques to improve the contrast and the sharpness of an image.
- \subpage tutorial-imgproc-autothreshold <br>This tutorial will show you different methods to automatically threshold, binarize an image.
- \subpage tutorial-imgproc-contour <br>This tutorial will show you how to extract the contours from a binary image.
- \subpage tutorial-imgproc-connected-components <br>This tutorial will show you how to do a connected-components labeling.
- \subpage tutorial-imgproc-flood-fill <br>This tutorial will show you how to use the flood fill algorithm.
- \subpage tutorial-imgproc-count-coins <br>This tutorial will show you how to count the number of coins in an image.
- \subpage tutorial-imgproc-cht <br>This tutorial will show you how to use the gradient-based Circle Hough Transform to detect circles in an image.
*/

/*! \page tutorial_calib Camera calibration
This page introduces the user to the way to calibrate a camera.

- \subpage tutorial-calibration-intrinsic <br>This tutorial explains how to calibrate intrinsic camera parameters.
- \subpage tutorial-calibration-extrinsic <br>This tutorial explains how to get the camera eye-in-hand extrinsic transformation when the camera is mounted on a robot end-effector.
*/

/*! \page tutorial_rendering 3D rendering and augmented reality
This page gives an introduction to using the 3D rendering tools integrated into ViSP.

- \subpage tutorial-panda3d <br>This tutorial gives an overview of the rendering capabilities of the Panda3D wrapper.
*/

/*! \page tutorial_tracking Tracking
This page introduces the user to the way to track objects in images.

- \subpage tutorial-tracking-blob <br>This tutorial introduces blob tracking and detection.
- \subpage tutorial-tracking-keypoint <br>This tutorial focuses on keypoint tracking using Kanade-Lucas-Tomasi feature tracker.
- \subpage tutorial-tracking-me <br>This tutorial focuses on line and ellipse tracking using moving-edges.
- \subpage tutorial-tracking-mb-generic <br>This tutorial focuses on model-based trackers using either moving edges, or keypoints, or a combination of them as visual features on images acquired by a monocular color camera.
- \subpage tutorial-tracking-mb-generic-stereo <br>This tutorial focuses on model-based trackers using either edges, or keypoints, or a combination of them as visual features on images acquired by a stereo color camera.
- \subpage tutorial-tracking-mb-generic-rgbd <br>This tutorial focuses on generic model-based trackers combining moving edges and/or keypoints with depth visual features.
- \subpage tutorial-tracking-mb-generic-apriltag-live <br>This tutorial is a simple use case. Using a webcam or an Intel RGB-D camera it shows how to test the generic model tracker on a cube that has an AprilTag glued on one face. The tag is here used to automate the tracker initialization.
- \subpage tutorial-mb-generic-json <br> This tutorial shows how to load and save the full tracker configuration from a json file.
- \subpage tutorial-tracking-mb-deprecated <br>This deprecated tutorial focuses on model-based trackers using either edges, keypoints or and hybrid scheme that uses edges and keypoints.
- \subpage tutorial-tracking-mb-CAO-editor <br>This tutorial presents the project done during the GSoC 2017: two Blender plugins to import/export .cao model file and a Qt-based .cao editor.
- \subpage tutorial-tracking-mb-generic-rgbd-Blender <br>This tutorial shows how to use Blender to generate simulated data to test the model-based tracker.
- \subpage tutorial-tracking-tt <br>This tutorial focuses on template trackers based on image registration approaches.
- \subpage tutorial-tracking-megapose <br>This tutorial shows how to use megapose, a deep learning pose estimation solution, to perform single object tracking.
- \subpage tutorial-megapose-model <br>This tutorial shows how to prepare your 3D model for usage in megapose after reconstruction with Neural Radiance Fields (NeRF).

*/

/*! \page tutorial_detection Detection
This page introduces the user to the way to detect features or objects in images.

- \subpage tutorial-matching <br>This tutorial shows how to detect and match keypoints.
- \subpage tutorial-detection-barcode <br>This tutorial focuses on bar code (QR code, Data Matrix code) detection.
- \subpage tutorial-detection-face <br>This tutorial focuses on face detection thanks to OpenCV Haar cascade classifier.
- \subpage tutorial-detection-object <br>This tutorial shows how to learn keypoints detected on a known object and how to use the matched correspondences to detect and estimate the pose of the object.
- \subpage tutorial-detection-object-deprecated <br>This tutorial shows how to learn keypoints detected on a known object and how to use the matched correspondences to detect and estimate the pose of the object. We recommend to follow rather \ref tutorial-detection-object that uses vpMbGenericTracker class.
- \subpage tutorial-detection-apriltag <br>This tutorial focuses on AprilTag patterns detection and pose estimation.

*/

/*! \page tutorial_detection_dnn DNN detection
This page introduces the user to the way to detect features or objects in images using Deep Neural Network (DNN).

- \subpage tutorial-detection-dnn <br>This tutorial shows how to do deep learning object detection.
- \subpage tutorial-detection-tensorrt <br>This tutorial shows how to perform object detection inference using NVIDIA TensorRT inference SDK.

*/

/*! \page tutorial_segmentation Segmentation
This page introduces the user to the way to achieve image and object segmentation.

- \subpage tutorial-hsv-segmentation-intro <br>This tutorial introduces how to use HSV color scale to segment a given
  color in an image.
- \subpage tutorial-hsv-range-tuner <br>This tutorial shows how to use HSV tuner tool to ease defining HSV
  how/high values used to select a given color either in a single image, or in a live stream provided by a Realsense
  camera.
- \subpage tutorial-hsv-segmentation-live <br>This tutorial illustrates how to use the HSV color scale to segment
  a given color in recorded or live video stream from a Realsense camera.
- \subpage tutorial-hsv-segmentation-pcl <br>This tutorial shows how to use the HSV color scale to segment
  a given color in recorded or live video stream from a Realsense camera and then compute the corresponding point cloud.
*/

/*! \page tutorial_computer_vision Computer vision
This page introduces the user to the way to estimate a pose or an homography.

- <a href="https://visp-doc.inria.fr/doxygen/camera_localization/">Pose estimation for augmented reality</a> <br>This tutorial is a self contented introduction to the most important approaches dedicated to camera localization along with a survey of the extension that have been proposed in the recent years. We also try to link these methodological concepts to the main libraries and SDK available on the market.
- \subpage tutorial-pose-estimation <br>This tutorial focuses on pose estimation from planar or non planar points.
- \subpage tutorial-pose-estimation-qrcode <br>This tutorial focuses on pose estimation of a QRcode using it's four corners location.
- \subpage tutorial-planar-object-pose <br>This tutorial shows how to estimate the pose of a planar object exploiting data (color and depth images) from a RGB-D sensor.
- \subpage tutorial-homography <br>Here we explain how to estimate an homography from couples of matched points.

*/

/*! \page tutorial_vs Visual servoing
This page introduces the user to the way to achieve a visual servoing.

- \subpage tutorial-ibvs <br>This tutorial explains how to simulate an IBVS.
- \subpage tutorial-simu-robot-pioneer <br>This tutorial focuses on visual servoing simulation on a unicycle robot. The study case is a Pioneer P3-DX mobile robot equipped with a camera.
- \subpage tutorial-boost-vs <br>This tutorial explains how to speed up the time to convergence of a visual servo.
- \subpage tutorial-franka-pbvs <br>This tutorial explains how to do a position-based visual-servoing with the Panda 7-dof robot from Franka Emika equipped with an Intel Realsense SR300 camera.
- \subpage tutorial-franka-ibvs <br>This tutorial explains how to do an image-based visual-servoing with the Panda 7-dof robot from Franka Emika equipped with an Intel Realsense SR300 camera.
- \subpage tutorial-franka-sim <br>This tutorial explains how to simulate a Panda 7-dof robot from Franka Emika for visual servoing and impedance control applications.
- \subpage tutorial-mbot-vs <br>This tutorial explains how to do a visual-servoing with the mBot Ranger educational robot kit equipped with a Raspberry Pi and a camera.
- \subpage tutorial-bebop2-vs <br> Explains how to implement an image-based visual-servoing (IBVS) with Parrot Bebop 2 drone.
- \subpage tutorial-flir-ptu-vs <br> Explains how to implement an image-based visual-servoing (IBVS) with Flir pan-tilt unit and camera.
- \subpage tutorial-universal-robot-ibvs <br> Provides information on controlling robots from Universal Robots using vpRobotUniversalRobots class implemented in ViSP and shows how to implement an image-based visual-servoing with such a robot.
- \subpage tutorial-universal-robot-pbvs <br> Explains how to implement a position-based visual-servoing with a robot from Universal Robots.
- \subpage tutorial-pixhawk-vs <br> Explains how to implement an image-based visual-servoing (IBVS) with a drone equipped with a Pixhaw,
  a Jetson TX2 and an Intel Realsense camera.
*/

/*! \page tutorial_bridge Bridges over other frameworks (OpenCV, MATLAB, ROS-1)
This page introduces the user the way to bridge other frameworks like OpenCV, MATLAB or ROS-1.

- \subpage tutorial-bridge-opencv <br>This tutorial explicit how to convert OpenCV to/from ViSP structures such as camera parameters, images...
- \subpage tutorial-visp-matlab <br>This tutorial shows how to invoke MATLAB functions from ViSP using MATLAB Engine.
- \subpage tutorial-bridge-ros <br>In this tutorial you will learn how to install ViSP prebuilt SDK for ROS and get pointers to existing ROS packages that are using ViSP.

*/

/*! \page tutorial_tools Other tools
This page introduces the user to other tools that may be useful.

- \subpage tutorial-plotter <br>This tutorial explains how to plot curves in real-time during a visual servo.
- \subpage tutorial-trace <br>This tutorial explains how to introduce trace in the code that could be enabled for debugging or disabled.
- \subpage tutorial-pcl-viewer <br>This tutorial explains how to use a threaded PCL-based point cloud visualizer.
- \subpage tutorial-json <br>This tutorial explains how to read and save data in the portable JSON format. It focuses on saving the data generated by a visual servoing experiment and exporting it to Python in order to generate plots.
- \subpage tutorial-synthetic-blenderproc <br> This tutorial shows you how to easily generate synthetic data from the 3D model of an object and obtain various modalities. This data can then be used to train a neural network for your own task.
- \subpage tutorial-spc <br> This tutorial shows you how to monitor if a signal is "in control" using Statistical Process Control methods.
- \subpage tutorial-ukf <br> This tutorial shows you how to use an Unscented Kalman Filter to filter data when the model and/or measurements are non-linear.
- \subpage tutorial-npz <br> This tutorial shows you how to read / save arrays of data from / to NPZ file format, a binary format compatible with the NumPy library.
*/

/*! \page tutorial_munkres Munkres Assignment Algorithm
This page introduces the user to the way to assign track points and detected points.

- \subpage tutorial-munkres <br>This tutorial explains how to use Munkres to assign tracked and detected image points.

*/

/*! \page tutorial_coding Contributing to ViSP source code
This page introduces the way ViSP source code can be modified with new contributions.

- \subpage tutorial-add-new-dependency <br>This tutorial explains how to introduce a new class that relies on a 3rd party SDK. Different use cases are given as example.

*/

/*! \page tutorial_contrib Extanding ViSP with contrib modules
This page introduces the way ViSP source code can be modified with new contributions.

- \subpage tutorial-contrib-module <br>This tutorial explains how to exploit ViSP modular architecture in order to introduce a new contrib module.

*/
